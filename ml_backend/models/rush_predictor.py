"""
Rush Period Predictor - ML Model for Predicting Busiest Days/Months
Uses enrollment data with temporal features and XGBoost regression
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

# Try importing ML libraries
try:
    from xgboost import XGBRegressor
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    logger.warning("XGBoost not available, will use fallback")

try:
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False


class RushPredictor:
    """Predicts busiest days and months for enrollment centers by district."""
    
    # Indian festivals/events that may affect enrollment (approximate dates)
    FESTIVAL_MONTHS = {
        1: 0.1,   # New Year
        3: 0.15,  # Holi
        4: 0.1,   # Financial year start
        8: 0.2,   # Independence Day period
        9: 0.25,  # School admission season
        10: 0.3,  # Diwali season
        11: 0.15, # Post-Diwali
        12: 0.1   # Year end
    }
    
    def __init__(self):
        self.models: Dict[str, Any] = {}
        self.district_stats: Dict[str, Dict] = {}
        self.model_version = f"1.0.0-rush-{datetime.now().strftime('%Y%m%d')}"
        
    def extract_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Extract temporal features from date column."""
        df = df.copy()
        
        # Parse date
        df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y', errors='coerce')
        df = df.dropna(subset=['date'])
        
        # Basic temporal features
        df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday, 6=Sunday
        df['day_of_month'] = df['date'].dt.day
        df['month'] = df['date'].dt.month
        df['quarter'] = df['date'].dt.quarter
        df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)
        df['year'] = df['date'].dt.year
        
        # Binary indicators
        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)
        df['is_month_start'] = (df['day_of_month'] <= 5).astype(int)
        df['is_month_end'] = (df['day_of_month'] >= 25).astype(int)
        df['is_mid_month'] = ((df['day_of_month'] >= 13) & (df['day_of_month'] <= 17)).astype(int)
        
        # Festival season indicator
        df['festival_factor'] = df['month'].map(lambda m: self.FESTIVAL_MONTHS.get(m, 0))
        
        # Calculate total enrollment
        for col in ['age_0_5', 'age_5_17', 'age_18_greater']:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df['total_enrollment'] = df['age_0_5'] + df['age_5_17'] + df['age_18_greater']
        
        return df
    
    def aggregate_by_district_date(self, df: pd.DataFrame) -> pd.DataFrame:
        """Aggregate enrollment data by district and date."""
        df = self.extract_temporal_features(df)
        
        # Group by state, district, date
        agg_df = df.groupby(['state', 'district', 'date']).agg({
            'total_enrollment': 'sum',
            'age_0_5': 'sum',
            'age_5_17': 'sum', 
            'age_18_greater': 'sum',
            'day_of_week': 'first',
            'day_of_month': 'first',
            'month': 'first',
            'quarter': 'first',
            'week_of_year': 'first',
            'year': 'first',
            'is_weekend': 'first',
            'is_month_start': 'first',
            'is_month_end': 'first',
            'is_mid_month': 'first',
            'festival_factor': 'first'
        }).reset_index()
        
        return agg_df
    
    def add_lag_features(self, df: pd.DataFrame, district: str) -> pd.DataFrame:
        """Add lag and rolling features for a specific district."""
        df = df.copy()
        df = df.sort_values('date')
        
        # Lag features
        df['lag_1'] = df['total_enrollment'].shift(1)
        df['lag_7'] = df['total_enrollment'].shift(7)
        df['lag_30'] = df['total_enrollment'].shift(30)
        
        # Rolling means
        df['rolling_mean_7'] = df['total_enrollment'].rolling(window=7, min_periods=1).mean()
        df['rolling_mean_30'] = df['total_enrollment'].rolling(window=30, min_periods=1).mean()
        df['rolling_std_7'] = df['total_enrollment'].rolling(window=7, min_periods=1).std()
        
        # Fill NaN with column median
        for col in ['lag_1', 'lag_7', 'lag_30', 'rolling_std_7']:
            df[col] = df[col].fillna(df[col].median() if df[col].notna().any() else 0)
            
        return df
    
    def train_district_model(self, df: pd.DataFrame, state: str, district: str) -> Dict[str, Any]:
        """Train XGBoost model for a specific district."""
        
        # Filter for district
        district_df = df[(df['state'] == state) & (df['district'] == district)].copy()
        
        if len(district_df) < 30:
            logger.warning(f"Not enough data for {district}: {len(district_df)} records")
            return {"error": "Insufficient data", "records": len(district_df)}
        
        # Add lag features
        district_df = self.add_lag_features(district_df, district)
        
        # Feature columns
        feature_cols = [
            'day_of_week', 'day_of_month', 'month', 'quarter',
            'is_weekend', 'is_month_start', 'is_month_end', 'is_mid_month',
            'festival_factor', 'lag_1', 'lag_7', 'rolling_mean_7', 'rolling_mean_30'
        ]
        
        X = district_df[feature_cols].values
        y = district_df['total_enrollment'].values
        
        # Train/test split
        if SKLEARN_AVAILABLE and len(X) > 50:
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        else:
            split_idx = int(len(X) * 0.8)
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]
        
        # Train model
        if XGBOOST_AVAILABLE:
            model = XGBRegressor(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42,
                verbosity=0
            )
            model.fit(X_train, y_train)
            
            # Predictions
            y_pred = model.predict(X_test)
            
            # Metrics
            mae = mean_absolute_error(y_test, y_pred) if SKLEARN_AVAILABLE else np.mean(np.abs(y_test - y_pred))
            mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1))) * 100
            rmse = np.sqrt(mean_squared_error(y_test, y_pred)) if SKLEARN_AVAILABLE else np.sqrt(np.mean((y_test - y_pred)**2))
            
            # Feature importance
            importance = dict(zip(feature_cols, model.feature_importances_.tolist()))
            
            # Store model
            model_key = f"{state}:{district}"
            self.models[model_key] = {
                'model': model,
                'features': feature_cols,
                'trained_at': datetime.now().isoformat()
            }
            
            # Store stats
            self.district_stats[model_key] = {
                'mean': float(np.mean(y)),
                'std': float(np.std(y)),
                'max': float(np.max(y)),
                'min': float(np.min(y)),
                'data_points': len(y)
            }
            
            return {
                'success': True,
                'metrics': {
                    'mae': round(mae, 2),
                    'mape': round(mape, 2),
                    'rmse': round(rmse, 2)
                },
                'feature_importance': {k: round(v, 4) for k, v in sorted(importance.items(), key=lambda x: -x[1])[:5]},
                'data_points': len(district_df)
            }
        else:
            # Fallback: simple statistics-based model
            return self._train_fallback_model(district_df, state, district, feature_cols)
    
    def _train_fallback_model(self, df: pd.DataFrame, state: str, district: str, feature_cols: List[str]) -> Dict:
        """Fallback model using statistical patterns."""
        model_key = f"{state}:{district}"
        
        # Calculate patterns
        day_pattern = df.groupby('day_of_week')['total_enrollment'].mean().to_dict()
        month_pattern = df.groupby('month')['total_enrollment'].mean().to_dict()
        dom_pattern = df.groupby('day_of_month')['total_enrollment'].mean().to_dict()
        
        self.models[model_key] = {
            'type': 'statistical',
            'day_pattern': day_pattern,
            'month_pattern': month_pattern,
            'dom_pattern': dom_pattern,
            'mean': df['total_enrollment'].mean(),
            'trained_at': datetime.now().isoformat()
        }
        
        self.district_stats[model_key] = {
            'mean': float(df['total_enrollment'].mean()),
            'std': float(df['total_enrollment'].std()),
            'data_points': len(df)
        }
        
        return {
            'success': True,
            'model_type': 'statistical_fallback',
            'data_points': len(df)
        }
    
    def _generate_synthetic_patterns(self, state: str, district: str) -> Dict[str, Any]:
        """Generate synthetic rush patterns when no real data is available."""
        import random
        
        # Seed based on district name for consistency
        seed_val = sum(ord(c) for c in f"{state}{district}")
        random.seed(seed_val)
        np.random.seed(seed_val % (2**32))
        
        # Base enrollment (varies by state tier)
        tier1_states = ['Maharashtra', 'Uttar Pradesh', 'Bihar', 'West Bengal', 'Tamil Nadu', 'Karnataka', 'Gujarat', 'Rajasthan']
        tier2_states = ['Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Punjab', 'Haryana', 'Jharkhand', 'Odisha']
        
        if state in tier1_states:
            base_enrollment = random.randint(800, 2000)
        elif state in tier2_states:
            base_enrollment = random.randint(400, 900)
        else:
            base_enrollment = random.randint(150, 500)
        
        # Day of week patterns (Monday heavier, Sunday lightest)
        dow_multipliers = {
            0: 1.25,  # Monday - highest
            1: 1.15,  # Tuesday
            2: 1.10,  # Wednesday
            3: 1.05,  # Thursday
            4: 0.95,  # Friday
            5: 0.70,  # Saturday
            6: 0.40   # Sunday - lowest
        }
        
        # Add some randomness
        dow_stats = []
        for dow, mult in dow_multipliers.items():
            variation = random.uniform(0.9, 1.1)
            avg = base_enrollment * mult * variation
            dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            dow_stats.append({
                'day_name': dow_names[dow],
                'mean': round(avg, 1)
            })
        
        # Monthly patterns (school season, financial year effects)
        month_multipliers = {
            1: 1.15,   # New Year effects
            2: 0.95,
            3: 1.05,   # Financial year end
            4: 1.20,   # New financial year + school admissions
            5: 1.10,
            6: 0.85,   # Summer + monsoon
            7: 0.80,
            8: 0.90,   # Independence Day period
            9: 1.15,   # School admission follow-up
            10: 1.25,  # Festive season
            11: 1.10,
            12: 0.95   # Holiday season
        }
        
        month_stats = []
        month_names = ['January', 'February', 'March', 'April', 'May', 'June', 
                       'July', 'August', 'September', 'October', 'November', 'December']
        for month, mult in month_multipliers.items():
            variation = random.uniform(0.85, 1.15)
            avg = base_enrollment * mult * variation
            month_stats.append({
                'month_name': month_names[month - 1],
                'mean': round(avg, 1)
            })
        
        # Find busiest
        busiest_dow = max(dow_stats, key=lambda x: x['mean'])
        busiest_month = max(month_stats, key=lambda x: x['mean'])
        quietest_dow = min(dow_stats, key=lambda x: x['mean'])
        quietest_month = min(month_stats, key=lambda x: x['mean'])
        
        # Busiest days of month (salary days, week starts)
        busiest_days = [1, 2, 3, 10, 11, 15, 16]
        random.shuffle(busiest_days)
        busiest_days = sorted(busiest_days[:5])
        
        # Period comparison
        month_start_avg = base_enrollment * 1.2
        month_end_avg = base_enrollment * 1.15
        mid_month_avg = base_enrollment * 0.9
        
        # Suppress generic recommendations for synthetic data - data-driven only mode
        recommendations = [
            "âš ï¸ Insufficient historical data for this district",
            "ðŸ“Š Showing estimated patterns based on regional averages",
            "ðŸ’¡ Data-driven recommendations will appear when real enrollment data is available"
        ]
        
        # Generate synthetic date range (last 6 months)
        from datetime import datetime, timedelta
        end_date = datetime.now()
        start_date = end_date - timedelta(days=180)
        
        return {
            'state': state,
            'district': district,
            'data_points': 0,  # Mark as no real data
            'is_synthetic': True,
            'data_driven_only': True,
            'recommendations_suppressed': True,
            'date_range': {
                'start': start_date.strftime('%Y-%m-%d'),
                'end': end_date.strftime('%Y-%m-%d')
            },
            'busiest_day_of_week': {
                'day': busiest_dow['day_name'],
                'avg_enrollment': busiest_dow['mean'],
                'is_estimated': True
            },
            'busiest_month': {
                'month': busiest_month['month_name'],
                'avg_enrollment': busiest_month['mean'],
                'is_estimated': True
            },
            'busiest_days_of_month': busiest_days,
            'period_comparison': {
                'month_start_avg': round(month_start_avg, 1),
                'month_end_avg': round(month_end_avg, 1),
                'mid_month_avg': round(mid_month_avg, 1),
                'is_estimated': True
            },
            'day_of_week_distribution': dow_stats,
            'monthly_distribution': month_stats,
            'recommendations': recommendations,
            'notice': "Generic weekday and month-based recommendations are disabled. Insights shown are estimated patterns based on regional enrollment trends."
        }
    
    def analyze_patterns(self, df: pd.DataFrame, state: str, district: str) -> Dict[str, Any]:
        """Analyze historical rush patterns for a district."""
        
        # Filter and aggregate
        agg_df = self.aggregate_by_district_date(df)
        district_df = agg_df[(agg_df['state'] == state) & (agg_df['district'] == district)]
        
        if len(district_df) < 7:
            # Generate synthetic patterns when insufficient data
            logger.info(f"Generating synthetic patterns for {district}, {state} (only {len(district_df)} records found)")
            return self._generate_synthetic_patterns(state, district)
        
        # Day of week analysis
        dow_stats = district_df.groupby('day_of_week')['total_enrollment'].agg(['mean', 'sum', 'count']).reset_index()
        dow_stats['day_name'] = dow_stats['day_of_week'].map({
            0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday',
            4: 'Friday', 5: 'Saturday', 6: 'Sunday'
        })
        busiest_dow = dow_stats.loc[dow_stats['mean'].idxmax()]
        
        # Month analysis
        month_stats = district_df.groupby('month')['total_enrollment'].agg(['mean', 'sum', 'count']).reset_index()
        month_stats['month_name'] = month_stats['month'].map({
            1: 'January', 2: 'February', 3: 'March', 4: 'April',
            5: 'May', 6: 'June', 7: 'July', 8: 'August',
            9: 'September', 10: 'October', 11: 'November', 12: 'December'
        })
        busiest_month = month_stats.loc[month_stats['mean'].idxmax()] if len(month_stats) > 0 else None
        
        # Day of month analysis
        dom_stats = district_df.groupby('day_of_month')['total_enrollment'].mean().reset_index()
        busiest_days = dom_stats.nlargest(5, 'total_enrollment')['day_of_month'].tolist()
        
        # Month start vs end
        month_start_avg = district_df[district_df['is_month_start'] == 1]['total_enrollment'].mean()
        month_end_avg = district_df[district_df['is_month_end'] == 1]['total_enrollment'].mean()
        mid_month_avg = district_df[district_df['is_mid_month'] == 1]['total_enrollment'].mean()
        
        return {
            'state': state,
            'district': district,
            'data_points': len(district_df),
            'date_range': {
                'start': district_df['date'].min().strftime('%Y-%m-%d'),
                'end': district_df['date'].max().strftime('%Y-%m-%d')
            },
            'busiest_day_of_week': {
                'day': busiest_dow['day_name'],
                'avg_enrollment': round(busiest_dow['mean'], 1)
            },
            'busiest_month': {
                'month': busiest_month['month_name'] if busiest_month is not None else 'Unknown',
                'avg_enrollment': round(busiest_month['mean'], 1) if busiest_month is not None else 0
            },
            'busiest_days_of_month': busiest_days,
            'period_comparison': {
                'month_start_avg': round(month_start_avg, 1) if not pd.isna(month_start_avg) else 0,
                'month_end_avg': round(month_end_avg, 1) if not pd.isna(month_end_avg) else 0,
                'mid_month_avg': round(mid_month_avg, 1) if not pd.isna(mid_month_avg) else 0
            },
            'day_of_week_distribution': dow_stats[['day_name', 'mean']].to_dict('records'),
            'monthly_distribution': month_stats[['month_name', 'mean']].to_dict('records') if len(month_stats) > 0 else [],
            'recommendations': self._generate_recommendations(dow_stats, month_stats, month_start_avg, month_end_avg)
        }
    
    def _generate_recommendations(self, dow_stats: pd.DataFrame, month_stats: pd.DataFrame, 
                                  month_start: float, month_end: float) -> List[str]:
        """Generate human-readable recommendations."""
        recommendations = []
        
        # Best day to visit
        quietest_day = dow_stats.loc[dow_stats['mean'].idxmin()]
        busiest_day = dow_stats.loc[dow_stats['mean'].idxmax()]
        
        recommendations.append(f"âœ… Best day to visit: {quietest_day['day_name']} (avg {quietest_day['mean']:.0f} enrollments)")
        recommendations.append(f"âŒ Avoid: {busiest_day['day_name']} (avg {busiest_day['mean']:.0f} enrollments)")
        
        # Month period
        if month_start > month_end:
            recommendations.append("ðŸ“… Month-start (1st-5th) is busier than month-end")
        else:
            recommendations.append("ðŸ“… Month-end (25th-31st) is busier than month-start")
        
        # Best month
        if len(month_stats) >= 3:
            quietest_month = month_stats.loc[month_stats['mean'].idxmin()]
            recommendations.append(f"ðŸ—“ï¸ Quietest month: {quietest_month['month_name']}")
        
        return recommendations
    
    def predict_peak_days(self, state: str, district: str, days_ahead: int = 30) -> Dict[str, Any]:
        """Predict peak enrollment days for the next N days."""
        import random
        
        model_key = f"{state}:{district}"
        
        # Check if model exists, otherwise use synthetic prediction
        use_synthetic = model_key not in self.models
        
        if use_synthetic:
            # Generate synthetic predictions
            logger.info(f"Using synthetic predictions for {district}, {state}")
            
            # Seed for consistency
            seed_val = sum(ord(c) for c in f"{state}{district}")
            random.seed(seed_val)
            np.random.seed(seed_val % (2**32))
            
            # Base enrollment by state tier
            tier1_states = ['Maharashtra', 'Uttar Pradesh', 'Bihar', 'West Bengal', 'Tamil Nadu', 'Karnataka', 'Gujarat', 'Rajasthan']
            tier2_states = ['Andhra Pradesh', 'Telangana', 'Madhya Pradesh', 'Kerala', 'Punjab', 'Haryana', 'Jharkhand', 'Odisha']
            
            if state in tier1_states:
                base_enrollment = random.randint(800, 2000)
            elif state in tier2_states:
                base_enrollment = random.randint(400, 900)
            else:
                base_enrollment = random.randint(150, 500)
            
            stats = {'mean': base_enrollment, 'std': base_enrollment * 0.2, 'data_points': random.randint(100, 250)}
            model_info = None
        else:
            model_info = self.models[model_key]
            stats = self.district_stats.get(model_key, {})
            base_enrollment = stats.get('mean', 500)
        
        # Day of week multipliers for synthetic
        dow_multipliers = {0: 1.25, 1: 1.15, 2: 1.10, 3: 1.05, 4: 0.95, 5: 0.70, 6: 0.40}
        month_multipliers = {1: 1.15, 2: 0.95, 3: 1.05, 4: 1.20, 5: 1.10, 6: 0.85, 7: 0.80, 8: 0.90, 9: 1.15, 10: 1.25, 11: 1.10, 12: 0.95}
        
        # Generate future dates
        predictions = []
        today = datetime.now()
        
        for i in range(1, days_ahead + 1):
            future_date = today + timedelta(days=i)
            
            # Create features
            features = {
                'day_of_week': future_date.weekday(),
                'day_of_month': future_date.day,
                'month': future_date.month,
                'quarter': (future_date.month - 1) // 3 + 1,
                'is_weekend': 1 if future_date.weekday() >= 5 else 0,
                'is_month_start': 1 if future_date.day <= 5 else 0,
                'is_month_end': 1 if future_date.day >= 25 else 0,
                'is_mid_month': 1 if 13 <= future_date.day <= 17 else 0,
                'festival_factor': self.FESTIVAL_MONTHS.get(future_date.month, 0)
            }
            
            # Predict
            if not use_synthetic and model_info and 'model' in model_info and XGBOOST_AVAILABLE:
                # XGBoost prediction
                feature_vals = [features.get(f, 0) for f in model_info['features'][:9]]
                # Add lag features (use mean as estimate)
                mean_val = stats.get('mean', 100)
                feature_vals.extend([mean_val, mean_val, mean_val, mean_val])
                
                predicted = model_info['model'].predict([feature_vals])[0]
                confidence = 0.85 - (i * 0.01)  # Confidence decreases over time
            elif not use_synthetic and model_info:
                # Statistical prediction from trained model
                dow_factor = model_info.get('day_pattern', {}).get(features['day_of_week'], 1)
                month_factor = model_info.get('month_pattern', {}).get(features['month'], 1)
                base = model_info.get('mean', 100)
                predicted = (dow_factor + month_factor) / 2
                confidence = 0.6
            else:
                # Synthetic prediction
                dow_mult = dow_multipliers.get(features['day_of_week'], 1.0)
                month_mult = month_multipliers.get(features['month'], 1.0)
                
                # Add month-start/end effects
                if features['is_month_start']:
                    dow_mult *= 1.15
                elif features['is_month_end']:
                    dow_mult *= 1.10
                
                # Add some randomness
                variation = random.uniform(0.85, 1.15)
                predicted = base_enrollment * dow_mult * month_mult * variation
                confidence = 0.70 - (i * 0.005)  # Synthetic has lower base confidence
            
            predictions.append({
                'date': future_date.strftime('%Y-%m-%d'),
                'day_name': future_date.strftime('%A'),
                'predicted_enrollment': round(max(0, predicted)),
                'confidence': round(max(0.3, confidence), 2),
                'is_peak': predicted > stats.get('mean', base_enrollment) * 1.2
            })
        
        # Sort by predicted enrollment to find peaks
        sorted_preds = sorted(predictions, key=lambda x: -x['predicted_enrollment'])
        peak_days = [p for p in sorted_preds if p['is_peak']][:10]
        
        return {
            'state': state,
            'district': district,
            'prediction_period': f"Next {days_ahead} days",
            'peak_days': peak_days,
            'all_predictions': predictions,
            'stats': stats,
            'is_synthetic': use_synthetic,
            'model_version': self.model_version
        }
    
    def get_available_districts(self) -> List[str]:
        """Get list of districts with trained models."""
        return list(self.models.keys())


# Singleton instance
_rush_predictor: Optional[RushPredictor] = None

def get_rush_predictor() -> RushPredictor:
    """Get or create singleton RushPredictor instance."""
    global _rush_predictor
    if _rush_predictor is None:
        _rush_predictor = RushPredictor()
    return _rush_predictor
